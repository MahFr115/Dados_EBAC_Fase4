{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee35cf2d-15f5-4b39-b26a-66a7b5f39b90",
   "metadata": {},
   "source": [
    "# EBAC \n",
    "## Módulo 24: Combinação de modelos II\n",
    "### Tarefa 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d6d1c3-b00d-432e-90d0-7b2f97178fd9",
   "metadata": {},
   "source": [
    "1. Cite 5 diferenças entre o Random Forest e o AdaBoost\n",
    "2. Acesse o link [Scikit-learn– adaboost](https://scikit-learn.org/stable/modules/ensemble.html?) , leia a explicação (traduza se for preciso) e crie um jupyter notebook contendo o exemplo do AdaBoost.\n",
    "3. Cite 5 Hyperparametros importantes no AdaBoost.\n",
    "4. (Opcional) Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf3bba03-7992-4e50-a7a1-423ebbe63dbc",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th> </th>\n",
    "        <th>RandomForest</th>\n",
    "        <th>AdaBoost</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Passos</th>\n",
    "        <td>Para cada divisão de base a árvore é completa.<br> <img src=https://media.geeksforgeeks.org/wp-content/uploads/20220403215158/77959.jpg width=\"600\"></td>\n",
    "        <td>Para cada passo a árvore criada é um fragmento da real.<br> <img src =https://media.geeksforgeeks.org/wp-content/uploads/20220403215159/3469.jpg width=\"490\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Dependência ddos modelos</th>\n",
    "        <td>Árvores independentes, que podem rodar em paralelo.</td>\n",
    "        <td>O desenvolvimentos dos Stumps dependem da performance do anterior.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Pesos</th>\n",
    "        <td>Todas a árvores criadas tem o mesmo peso.</td>\n",
    "        <td>Cada árvore tem, um peso que depende da performance do Stump anterio.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Amostragem de dados</th>\n",
    "        <td>Técnica de empacotamento.</td>\n",
    "        <td>Baseada em reforço.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Overfitting</th>\n",
    "        <td>Menos sensível se com parado ao AdaBoost.</td>\n",
    "        <td>Menos tolerante se comparado ao RandomForest.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Estimativa</th>\n",
    "        <td>Visa reduzir a variância.</td>\n",
    "        <td>Visa reduzir o viés.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Acurância de Classificação</th>\n",
    "        <td>Tem pior acurância para árvores de classificação.</td>\n",
    "        <td>Tem melhor acurância para árvores de classificação.</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db034c1b-3237-4dc7-9801-ec7625abfe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo: Load_Iris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Exemplo: Load_Iris\")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier(n_estimators=100, algorithm='SAMME')\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e66e83-5571-417a-920a-6459208e9d61",
   "metadata": {},
   "source": [
    "Hyperparâmetros do AdaBoost:\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Hyperparâmetros</th>\n",
    "        <th>Variável</th>\n",
    "        <th>Tipo</th>\n",
    "        <th>Explicação</th>\n",
    "        <th>Valores Frequêntes</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Função</th>\n",
    "        <td>estimator</td>\n",
    "        <td>object</td>\n",
    "        <td>A função base de estimativa apartir da qual o boosted é desenvolvido.</td>\n",
    "        <td>- default: DecisionTreeClassifier<br>- comuns: LogisticRegression</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Número de Estimativas</th>\n",
    "        <td>n_estimators</td>\n",
    "        <td>int</td>\n",
    "        <td>O número máximo de estimátivas em que cada boosting é determindo. <br>\n",
    "            <font color = \"red\">Obs: Se o encaixe é perfeito o aprendizado temina antecipadamente.</font></td>\n",
    "        <td>- default: 50<br>- comuns: 50 à 300</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Taxa de Aprendizado</th>\n",
    "        <td>learning_rate</td>\n",
    "        <td>float</td>\n",
    "        <td>Taxa de aprendizado que pondera a contibuição de cada estimador.</td>\n",
    "        <td>- default: 1.0<br>- comuns: [0.01, 0.1, 0.5, 1.0]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Algorítmo</th>\n",
    "        <td>algorithm</td>\n",
    "        <td>object</td>\n",
    "        <td>Algorítmo de cálculo dos resultados.</td>\n",
    "        <td>- default: \"SAMME\"<br>- comuns: \"SAMME.R\"</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Reprodutibilidade dos Resultados</th>\n",
    "        <td>random_state</td>\n",
    "        <td>int</td>\n",
    "        <td>Define a semente (seed) para os geradores de números aleatórios utilizados internamente, como na amostragem de dados, na seleção de features ou no treinamento de estimadores base.</td>\n",
    "        <td>- default: None<br>- comuns: 42</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Profundidade Máxima</th>\n",
    "        <td>max_depth</td>\n",
    "        <td>int</td>\n",
    "        <td>Profundidade máxima da árvores, quantidade de níveis de divisão do desenvolvimento da árvore.</td>\n",
    "        <td>- default: 1<br>-comuns: [2, 3, 5, 10]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Qtd. de Amostras para Dividir um Nó</th>\n",
    "        <td>min_samples_split</td>\n",
    "        <td>int</td>\n",
    "        <td>Número mínimo de amostragens de dvivisão entre os desenvolvimentos dos nós.</td>\n",
    "        <td>- default: 2<br>- comuns: [5, 10 à 0,01]</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760780dd-93e0-4c7d-9699-133f68bf9a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch no exemplo load_iris:\n",
      "Best parameters: {'learning_rate': 0.1, 'n_estimators': 150, 'random_state': None}\n",
      "Best score: 0.9600\n"
     ]
    }
   ],
   "source": [
    "print(\"GridSearch no exemplo load_iris:\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# AdaBoost com modelo base\n",
    "ada = AdaBoostClassifier(algorithm = 'SAMME')\n",
    "\n",
    "# Hiperparâmetros para testar\n",
    "parameters = {\n",
    "    'n_estimators': list(range(50, 301, 50)),  \n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'random_state': [None, 42]\n",
    "}\n",
    "\n",
    "# GridSearch\n",
    "clf = GridSearchCV(ada, parameters, cv=5)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Best parameters: {clf.best_params_}\")\n",
    "print(f\"Best score: {clf.best_score_:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
